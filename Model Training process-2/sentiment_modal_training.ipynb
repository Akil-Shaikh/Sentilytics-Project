{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/akil/Desktop/Model Training process-2/new_data_with_sentiment (1).csv\")\n",
    "df=df[['text','new_label']]\n",
    "df.dropna(inplace=True)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'LABEL_0': 0, 'LABEL_1': 1, 'LABEL_2': 2}  # Modify based on your labels\n",
    "df['new_label'] = df['new_label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "new_label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "e3ce8120-424f-4be5-ad6f-5f1eed5af1f8",
       "rows": [
        [
         "0",
         "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D",
         "0"
        ],
        [
         "1",
         "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!",
         "0"
        ],
        [
         "2",
         "@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds",
         "1"
        ],
        [
         "3",
         "my whole body feels itchy and like its on fire ",
         "0"
        ],
        [
         "4",
         "@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. ",
         "0"
        ],
        [
         "5",
         "@Kwesidei not the whole crew ",
         "1"
        ],
        [
         "6",
         "Need a hug ",
         "1"
        ],
        [
         "7",
         "@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?",
         "2"
        ],
        [
         "8",
         "@Tatiana_K nope they didn't have it ",
         "1"
        ],
        [
         "9",
         "@twittera que me muera ? ",
         "1"
        ],
        [
         "10",
         "spring break in plain city... it's snowing ",
         "1"
        ],
        [
         "11",
         "I just re-pierced my ears ",
         "1"
        ],
        [
         "12",
         "@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .",
         "0"
        ],
        [
         "13",
         "@octolinz16 It it counts, idk why I did either. you never talk to me anymore ",
         "0"
        ],
        [
         "14",
         "@smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.",
         "0"
        ],
        [
         "15",
         "@iamjazzyfizzle I wish I got to watch it with you!! I miss you and @iamlilnicki  how was the premiere?!",
         "2"
        ],
        [
         "16",
         "Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?",
         "0"
        ],
        [
         "17",
         "about to file taxes ",
         "1"
        ],
        [
         "18",
         "@LettyA ahh ive always wanted to see rent  love the soundtrack!!",
         "2"
        ],
        [
         "19",
         "@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks? ",
         "1"
        ],
        [
         "20",
         "@alydesigns i was out most of the day so didn't get much done ",
         "0"
        ],
        [
         "21",
         "one of my friend called me, and asked to meet with her at Mid Valley today...but i've no time *sigh* ",
         "0"
        ],
        [
         "22",
         "@angry_barista I baked you a cake but I ated it ",
         "1"
        ],
        [
         "23",
         "this week is not going as i had hoped ",
         "0"
        ],
        [
         "24",
         "blagh class at 8 tomorrow ",
         "1"
        ],
        [
         "25",
         "I hate when I have to call and wake people up ",
         "0"
        ],
        [
         "26",
         "Just going to cry myself to sleep after watching Marley and Me.  ",
         "1"
        ],
        [
         "27",
         "im sad now  Miss.Lilly",
         "0"
        ],
        [
         "28",
         "ooooh.... LOL  that leslie.... and ok I won't do it again so leslie won't  get mad again ",
         "1"
        ],
        [
         "29",
         "Meh... Almost Lover is the exception... this track gets me depressed every time. ",
         "0"
        ],
        [
         "30",
         "some1 hacked my account on aim  now i have to make a new one",
         "0"
        ],
        [
         "31",
         "@alielayus I want to go to promote GEAR AND GROOVE but unfornately no ride there  I may b going to the one in Anaheim in May though",
         "1"
        ],
        [
         "32",
         "thought sleeping in was an option tomorrow but realizing that it now is not. evaluations in the morning and work in the afternoon! ",
         "1"
        ],
        [
         "33",
         "@julieebaby awe i love you too!!!! 1 am here  i miss you",
         "2"
        ],
        [
         "34",
         "@HumpNinja I cry my asian eyes to sleep at night ",
         "0"
        ],
        [
         "35",
         "ok I'm sick and spent an hour sitting in the shower cause I was too sick to stand and held back the puke like a champ. BED now ",
         "0"
        ],
        [
         "36",
         "@cocomix04 ill tell ya the story later  not a good day and ill be workin for like three more hours...",
         "0"
        ],
        [
         "37",
         "@MissXu sorry! bed time came here (GMT+1)   http://is.gd/fNge",
         "0"
        ],
        [
         "38",
         "@fleurylis I don't either. Its depressing. I don't think I even want to know about the kids in suitcases. ",
         "0"
        ],
        [
         "39",
         "Bed. Class 8-12. Work 12-3. Gym 3-5 or 6. Then class 6-10. Another day that's gonna fly by. I miss my girlfriend ",
         "0"
        ],
        [
         "40",
         "really don't feel like getting up today... but got to study to for tomorrows practical exam... ",
         "0"
        ],
        [
         "41",
         "He's the reason for the teardrops on my guitar the only one who has enough of me to break my heart ",
         "1"
        ],
        [
         "42",
         "Sad, sad, sad. I don't know why but I hate this feeling  I wanna sleep and I still can't!",
         "0"
        ],
        [
         "43",
         "@JonathanRKnight Awww I soo wish I was there to see you finally comfortable! Im sad that I missed it ",
         "0"
        ],
        [
         "44",
         "Falling asleep. Just heard about that Tracy girl's body being found. How sad  My heart breaks for that family.",
         "0"
        ],
        [
         "45",
         "@Viennah Yay! I'm happy for you with your job! But that also means less time for me and you... ",
         "2"
        ],
        [
         "46",
         "Just checked my user timeline on my blackberry, it looks like the twanking is still happening  Are ppl still having probs w/ BGs and UIDs?",
         "1"
        ],
        [
         "47",
         "Oh man...was ironing @jeancjumbe's fave top to wear to a meeting. Burnt it ",
         "0"
        ],
        [
         "48",
         "is strangely sad about LiLo and SamRo breaking up. ",
         "0"
        ],
        [
         "49",
         "@tea oh! i'm so sorry  i didn't think about that before retweeting.",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 1981441
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>new_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000053</th>\n",
       "      <td>We bought this Thomas for our son who is a hug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000054</th>\n",
       "      <td>My son recieved this as a birthday gift 2 mont...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000055</th>\n",
       "      <td>I bought this toy for my son who loves the \"Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000056</th>\n",
       "      <td>This is a compilation of a wide range of Mitfo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000057</th>\n",
       "      <td>This DVD will be a disappointment if you get i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1981441 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  new_label\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...          0\n",
       "1        is upset that he can't update his Facebook by ...          0\n",
       "2        @Kenichan I dived many times for the ball. Man...          1\n",
       "3          my whole body feels itchy and like its on fire           0\n",
       "4        @nationwideclass no, it's not behaving at all....          0\n",
       "...                                                    ...        ...\n",
       "2000053  We bought this Thomas for our son who is a hug...          1\n",
       "2000054  My son recieved this as a birthday gift 2 mont...          0\n",
       "2000055  I bought this toy for my son who loves the \"Th...          0\n",
       "2000056  This is a compilation of a wide range of Mitfo...          2\n",
       "2000057  This DVD will be a disappointment if you get i...          0\n",
       "\n",
       "[1981441 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\akil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\akil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\akil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.stop_words = set(stopwords.words(\"english\"))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.regex_pattern = re.compile(r\"http\\S+|www\\S+|@\\w+|#\\w+|[^\\w\\s]|\\d+\")\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        text = text.lower()\n",
    "        text = self.regex_pattern.sub(\"\", text)\n",
    "        tokens = word_tokenize(text)\n",
    "        cleaned_tokens = []\n",
    "        negate = False\n",
    "        negation_words = {\"not\", \"no\", \"never\", \"n't\"}\n",
    "        for word in tokens:\n",
    "            if word in negation_words:\n",
    "                negate = True\n",
    "            elif negate:\n",
    "                cleaned_tokens.append(\n",
    "                    \"not_\" + self.lemmatizer.lemmatize(word)\n",
    "                )\n",
    "                negate = False\n",
    "            elif word not in self.stop_words:\n",
    "                cleaned_tokens.append(self.lemmatizer.lemmatize(word))\n",
    "\n",
    "        return \" \".join(cleaned_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not_like movie horrible\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor()\n",
    "text = \"I do not like movie at all! It was horrible 😡\"\n",
    "print(preprocessor.clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_text']=df['text'].apply(preprocessor.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "new_label",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "cleaned_text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "cfc80826-2600-4a99-b11a-f75d092ab273",
       "rows": [
        [
         "0",
         "@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D",
         "0",
         "thats bummer shoulda got david carr third day"
        ],
        [
         "1",
         "is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!",
         "0",
         "upset cant update facebook texting might cry result school today also blah"
        ],
        [
         "2",
         "@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds",
         "1",
         "dived many time ball managed save rest go bound"
        ],
        [
         "3",
         "my whole body feels itchy and like its on fire ",
         "0",
         "whole body feel itchy like fire"
        ],
        [
         "4",
         "@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there. ",
         "0",
         "not_it not_behaving im mad cant see"
        ],
        [
         "5",
         "@Kwesidei not the whole crew ",
         "1",
         "not_the whole crew"
        ],
        [
         "6",
         "Need a hug ",
         "1",
         "need hug"
        ],
        [
         "7",
         "@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?",
         "2",
         "hey long time not_see yes rain bit bit lol im fine thanks hows"
        ],
        [
         "8",
         "@Tatiana_K nope they didn't have it ",
         "1",
         "nope didnt"
        ],
        [
         "9",
         "@twittera que me muera ? ",
         "1",
         "que muera"
        ],
        [
         "10",
         "spring break in plain city... it's snowing ",
         "1",
         "spring break plain city snowing"
        ],
        [
         "11",
         "I just re-pierced my ears ",
         "1",
         "repierced ear"
        ],
        [
         "12",
         "@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .",
         "0",
         "couldnt bear watch thought ua loss embarrassing"
        ],
        [
         "13",
         "@octolinz16 It it counts, idk why I did either. you never talk to me anymore ",
         "0",
         "count idk either not_talk anymore"
        ],
        [
         "14",
         "@smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.",
         "0",
         "wouldve first didnt gun not_really though zac snyders doucheclown"
        ],
        [
         "15",
         "@iamjazzyfizzle I wish I got to watch it with you!! I miss you and @iamlilnicki  how was the premiere?!",
         "2",
         "wish got watch miss premiere"
        ],
        [
         "16",
         "Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?",
         "0",
         "hollis death scene hurt severely watch film wry director cut not_out"
        ],
        [
         "17",
         "about to file taxes ",
         "1",
         "file tax"
        ],
        [
         "18",
         "@LettyA ahh ive always wanted to see rent  love the soundtrack!!",
         "2",
         "ahh ive always wanted see rent love soundtrack"
        ],
        [
         "19",
         "@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks? ",
         "1",
         "oh dear drinking forgotten table drink"
        ],
        [
         "20",
         "@alydesigns i was out most of the day so didn't get much done ",
         "0",
         "day didnt get much done"
        ],
        [
         "21",
         "one of my friend called me, and asked to meet with her at Mid Valley today...but i've no time *sigh* ",
         "0",
         "one friend called asked meet mid valley todaybut ive not_time sigh"
        ],
        [
         "22",
         "@angry_barista I baked you a cake but I ated it ",
         "1",
         "baked cake ated"
        ],
        [
         "23",
         "this week is not going as i had hoped ",
         "0",
         "week not_going hoped"
        ],
        [
         "24",
         "blagh class at 8 tomorrow ",
         "1",
         "blagh class tomorrow"
        ],
        [
         "25",
         "I hate when I have to call and wake people up ",
         "0",
         "hate call wake people"
        ],
        [
         "26",
         "Just going to cry myself to sleep after watching Marley and Me.  ",
         "1",
         "going cry sleep watching marley"
        ],
        [
         "27",
         "im sad now  Miss.Lilly",
         "0",
         "im sad misslilly"
        ],
        [
         "28",
         "ooooh.... LOL  that leslie.... and ok I won't do it again so leslie won't  get mad again ",
         "1",
         "ooooh lol leslie ok wont leslie wont get mad"
        ],
        [
         "29",
         "Meh... Almost Lover is the exception... this track gets me depressed every time. ",
         "0",
         "meh almost lover exception track get depressed every time"
        ],
        [
         "30",
         "some1 hacked my account on aim  now i have to make a new one",
         "0",
         "hacked account aim make new one"
        ],
        [
         "31",
         "@alielayus I want to go to promote GEAR AND GROOVE but unfornately no ride there  I may b going to the one in Anaheim in May though",
         "1",
         "want go promote gear groove unfornately not_ride may b going one anaheim may though"
        ],
        [
         "32",
         "thought sleeping in was an option tomorrow but realizing that it now is not. evaluations in the morning and work in the afternoon! ",
         "1",
         "thought sleeping option tomorrow realizing not_evaluation morning work afternoon"
        ],
        [
         "33",
         "@julieebaby awe i love you too!!!! 1 am here  i miss you",
         "2",
         "awe love miss"
        ],
        [
         "34",
         "@HumpNinja I cry my asian eyes to sleep at night ",
         "0",
         "cry asian eye sleep night"
        ],
        [
         "35",
         "ok I'm sick and spent an hour sitting in the shower cause I was too sick to stand and held back the puke like a champ. BED now ",
         "0",
         "ok im sick spent hour sitting shower cause sick stand held back puke like champ bed"
        ],
        [
         "36",
         "@cocomix04 ill tell ya the story later  not a good day and ill be workin for like three more hours...",
         "0",
         "ill tell ya story later not_a good day ill workin like three hour"
        ],
        [
         "37",
         "@MissXu sorry! bed time came here (GMT+1)   http://is.gd/fNge",
         "0",
         "sorry bed time came gmt"
        ],
        [
         "38",
         "@fleurylis I don't either. Its depressing. I don't think I even want to know about the kids in suitcases. ",
         "0",
         "dont either depressing dont think even want know kid suitcase"
        ],
        [
         "39",
         "Bed. Class 8-12. Work 12-3. Gym 3-5 or 6. Then class 6-10. Another day that's gonna fly by. I miss my girlfriend ",
         "0",
         "bed class work gym class another day thats gon na fly miss girlfriend"
        ],
        [
         "40",
         "really don't feel like getting up today... but got to study to for tomorrows practical exam... ",
         "0",
         "really dont feel like getting today got study tomorrow practical exam"
        ],
        [
         "41",
         "He's the reason for the teardrops on my guitar the only one who has enough of me to break my heart ",
         "1",
         "he reason teardrop guitar one enough break heart"
        ],
        [
         "42",
         "Sad, sad, sad. I don't know why but I hate this feeling  I wanna sleep and I still can't!",
         "0",
         "sad sad sad dont know hate feeling wan na sleep still cant"
        ],
        [
         "43",
         "@JonathanRKnight Awww I soo wish I was there to see you finally comfortable! Im sad that I missed it ",
         "0",
         "awww soo wish see finally comfortable im sad missed"
        ],
        [
         "44",
         "Falling asleep. Just heard about that Tracy girl's body being found. How sad  My heart breaks for that family.",
         "0",
         "falling asleep heard tracy girl body found sad heart break family"
        ],
        [
         "45",
         "@Viennah Yay! I'm happy for you with your job! But that also means less time for me and you... ",
         "2",
         "yay im happy job also mean less time"
        ],
        [
         "46",
         "Just checked my user timeline on my blackberry, it looks like the twanking is still happening  Are ppl still having probs w/ BGs and UIDs?",
         "1",
         "checked user timeline blackberry look like twanking still happening ppl still probs w bgs uids"
        ],
        [
         "47",
         "Oh man...was ironing @jeancjumbe's fave top to wear to a meeting. Burnt it ",
         "0",
         "oh manwas ironing fave top wear meeting burnt"
        ],
        [
         "48",
         "is strangely sad about LiLo and SamRo breaking up. ",
         "0",
         "strangely sad lilo samro breaking"
        ],
        [
         "49",
         "@tea oh! i'm so sorry  i didn't think about that before retweeting.",
         "0",
         "oh im sorry didnt think retweeting"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 1981441
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>new_label</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>0</td>\n",
       "      <td>thats bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>1</td>\n",
       "      <td>dived many time ball managed save rest go bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>0</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>0</td>\n",
       "      <td>not_it not_behaving im mad cant see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000053</th>\n",
       "      <td>We bought this Thomas for our son who is a hug...</td>\n",
       "      <td>1</td>\n",
       "      <td>bought thomas son huge thomas fan huge set roo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000054</th>\n",
       "      <td>My son recieved this as a birthday gift 2 mont...</td>\n",
       "      <td>0</td>\n",
       "      <td>son recieved birthday gift month ago loved eve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000055</th>\n",
       "      <td>I bought this toy for my son who loves the \"Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>bought toy son love thomas toy need one batter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000056</th>\n",
       "      <td>This is a compilation of a wide range of Mitfo...</td>\n",
       "      <td>2</td>\n",
       "      <td>compilation wide range mitford article best sk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000057</th>\n",
       "      <td>This DVD will be a disappointment if you get i...</td>\n",
       "      <td>0</td>\n",
       "      <td>dvd disappointment get hoping see substantial ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1981441 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  new_label  \\\n",
       "0        @switchfoot http://twitpic.com/2y1zl - Awww, t...          0   \n",
       "1        is upset that he can't update his Facebook by ...          0   \n",
       "2        @Kenichan I dived many times for the ball. Man...          1   \n",
       "3          my whole body feels itchy and like its on fire           0   \n",
       "4        @nationwideclass no, it's not behaving at all....          0   \n",
       "...                                                    ...        ...   \n",
       "2000053  We bought this Thomas for our son who is a hug...          1   \n",
       "2000054  My son recieved this as a birthday gift 2 mont...          0   \n",
       "2000055  I bought this toy for my son who loves the \"Th...          0   \n",
       "2000056  This is a compilation of a wide range of Mitfo...          2   \n",
       "2000057  This DVD will be a disappointment if you get i...          0   \n",
       "\n",
       "                                              cleaned_text  \n",
       "0            thats bummer shoulda got david carr third day  \n",
       "1        upset cant update facebook texting might cry r...  \n",
       "2          dived many time ball managed save rest go bound  \n",
       "3                          whole body feel itchy like fire  \n",
       "4                      not_it not_behaving im mad cant see  \n",
       "...                                                    ...  \n",
       "2000053  bought thomas son huge thomas fan huge set roo...  \n",
       "2000054  son recieved birthday gift month ago loved eve...  \n",
       "2000055  bought toy son love thomas toy need one batter...  \n",
       "2000056  compilation wide range mitford article best sk...  \n",
       "2000057  dvd disappointment get hoping see substantial ...  \n",
       "\n",
       "[1981441 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/akil/Desktop/Model Training process-2/clean_data.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/akil/Desktop/Model Training process-2/clean_data.csv\")#----------------------------------------------\n",
    "df = df.dropna(subset=['cleaned_text'])  # Remove rows where 'cleaned_text' is NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_text'], df['new_label'], test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=200000)  # Limit features to 200K words\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7720\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.77      0.79    131875\n",
      "           1       0.61      0.75      0.68    103524\n",
      "           2       0.88      0.78      0.83    159462\n",
      "\n",
      "    accuracy                           0.77    394861\n",
      "   macro avg       0.77      0.77      0.77    394861\n",
      "weighted avg       0.79      0.77      0.78    394861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=500, class_weight='balanced')  # Balanced handles class imbalance\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic model and vectorizer saved successfully!\n"
     ]
    }
   ],
   "source": [
    "with open(\"C:/Users/akil/Desktop/Model Training process-2/sentiment_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "with open(\"C:/Users/akil/Desktop/Model Training process-2/tfidf_vectorizer.pkl\", \"wb\") as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)\n",
    "\n",
    "print(\"Logistic model and vectorizer saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
